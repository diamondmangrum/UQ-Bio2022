{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UQBio_2022_1_1_Basic Image Processing ",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKSdkHsA_Wv_"
      },
      "source": [
        "# Tutorial 1_1 - Basic Image manipulation in a Python interactive notebook.\n",
        "\n",
        "----------\n",
        "## UQBio Summer School 2022\n",
        "--------------\n",
        "\n",
        "```\n",
        "Instructor: Luis Aguilera\n",
        "Author: Luis Aguilera\n",
        "Contact Info: luis.aguilera@colostate.edu\n",
        "\n",
        "Copyright (c) 2022 Dr. Brian Munsky. \n",
        "Dr. Luis Aguilera, Will Raymond\n",
        "Colorado State University.\n",
        "Licensed under BSD-3-Clause license.:\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLhGsyu8hgIP"
      },
      "source": [
        "<img src= https://github.com/MunskyGroup/uqbio2022/raw/master/files/files_image_processing/module_1_1/images/Slide1.png alt=\"drawing\" width=\"1200\"/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmGRxtCzqWqs"
      },
      "source": [
        "# Abstract \n",
        "\n",
        "This notebook provides a list of procedures to analyze microscope images. The notebook describes what a digital image is, and how to extract relevant information from the image. At the end of the tutorial, the student is expected to acquire the computational skills to implement the following list of objectives independently.\n",
        "\n",
        "## List of objectives\n",
        "\n",
        "\n",
        "1. Load the python modules commonly used to work with microscope data.\n",
        "2. Understand and explain what a digital image is in terms of matrices and tensors.\n",
        "3. Understand and explain what a monochromatic image is and a color image is.\n",
        "4. Select and slice the dimensions in a sequence of microscope images.\n",
        "5. Apply differents filters to remove noise from an image using linear algebra operations.\n",
        "6. Perform basic mathematic operations involved in image processing, including rotation, translation, and scaling. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MabWJ6vkA5Dh"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XltNqo0PlDt"
      },
      "source": [
        "The following lines of code import and install some libraries. For more information, look at the library name on the  Python Package Index [(PyPI)](https://pypi.org/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUp21jU285ef"
      },
      "source": [
        "# Loading libraries\n",
        "import random\n",
        "import matplotlib.pyplot as plt             # Library used for plotting\n",
        "from matplotlib.patches import Rectangle    # Module to plot a rectangle in the image\n",
        "import urllib.request                       # Library to download data\n",
        "import numpy as np                          # Library for array manipulation\n",
        "import seaborn as sn                        # Library for advanced plotting\n",
        "import pandas as pd                         # Library to manipulate data frames\n",
        "import tifffile                             # Library to store numpy arrays as TIFF\n",
        "import pathlib                              # Library to work with file paths\n",
        "from pathlib import Path                    # Library to work with file paths\n",
        "import skimage                              # Library for image manipulation. scikit-image\n",
        "from skimage.io import imread               # Module from skimage\n",
        "from matplotlib import animation            # Module to plot animations\n",
        "import ipywidgets as widgets                # Library to create widgets \n",
        "from ipywidgets import interact, interactive, HBox, Layout, VBox # Importing modules and functions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "participants = ['Abdulai  Gassama','Ning Zhao','Linda Forero','Will Raymond','Michael May','Ashok Prasad','Eric Ron','Joshua Cook','Ania Baetica','Antonio Matas', 'Athina Diakogianni', 'Ban', 'Lisa Weber','Brian Munsky', 'Carl Zhou', 'Cheyanne Evans', 'Daniel Ramirez', 'Diana Coroiu','Donghyun Jeong','Emmanuel Kennedy','Gordin D','Henry  Plamondon','Hollie Hindley','Jaspreet','Jhon Wu','Jushawn Macon', 'Kaan Ocal','Kathryn Hanfelt','Kristina Tang', 'Manuel Cortes', 'Mario Sanchez','Michael Alexander Ramirez','Michael Yang','Moe Obaid', 'Sam McDonald','Zachary Mouton', 'Zhang Xu']"
      ],
      "metadata": {
        "id": "K3jGYDf50dZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.choice(participants)"
      ],
      "metadata": {
        "id": "S7-k93i6FR4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A library is a collection of code to perform a specific task. For example, check the [scikit-image library webpage](https://scikit-image.org). \n",
        "\n"
      ],
      "metadata": {
        "id": "Nxsu81OwX90z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Python is the most popular programming language in data science, and the most popular programming language in CS [tiobe-index](https://www.tiobe.com/tiobe-index/). \n",
        "\n",
        "\n",
        "Python is an ecosistem with a comprensive list of well-mantanined libraries."
      ],
      "metadata": {
        "id": "H6LteMHOZhYL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src= https://numpy.org/images/content_images/ds-landscape.png alt=\"drawing\" width=\"1200\"/>"
      ],
      "metadata": {
        "id": "APoMxFVJPuhj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "During UQ-bio summer school we will be constantly using [NumPy](https://numpy.org), [Matplotlib](https://matplotlib.org),\n",
        "[Scipy](https://scipy.org), [Pandas](https://pandas.pydata.org), [Scikit-Image](https://scikit-image.org), [TensorFlow](https://www.tensorflow.org), etc."
      ],
      "metadata": {
        "id": "b0bpOUUXYRna"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src= https://github.com/MunskyGroup/uqbio2022/raw/master/files/files_image_processing/module_1_1/images/Slide8.png alt=\"drawing\" width=\"1200\"/>"
      ],
      "metadata": {
        "id": "_MELY2-aGpmR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.choice(participants)"
      ],
      "metadata": {
        "id": "gH52odcAGS3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you have problems understanding these concepts, please check this [tutorial](https://colab.research.google.com/drive/12Y_CjqZ3XB5WPkgs9VO2OYPNqyvUsdM7?usp=sharing) on basic Python. Also check this link for [cheatsheets](https://www.datacamp.com/resources/data-science-and-analytics-cheatsheets).\n"
      ],
      "metadata": {
        "id": "B5aGYstAIyN7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Working with images in python"
      ],
      "metadata": {
        "id": "xF80TYlZarBB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ms-rgCqfiyPE"
      },
      "source": [
        "<img src= https://github.com/MunskyGroup/uqbio2022/raw/master/files/files_image_processing/module_1_1/images/Slide2.png alt=\"drawing\" width=\"1200\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image modified from: Gonzalez, Rafael & Faisal, Zahraa. (2019). Digital Image Processing Second Edition. "
      ],
      "metadata": {
        "id": "q5WNA54G_Sdd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rw73zKSSzxS"
      },
      "source": [
        "## Downloading, opening, and visualizing images \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CryOMGJyTJKW"
      },
      "source": [
        "# Downloading the image from figshare SupFig1c_BG_MAX_Cell04.tif\n",
        "urls = ['https://ndownloader.figshare.com/files/26751209','https://ndownloader.figshare.com/files/26751203','https://ndownloader.figshare.com/files/26751212','https://ndownloader.figshare.com/files/26751218']\n",
        "print('Downloading file...')\n",
        "urllib.request.urlretrieve(urls[1], './image_cell.tif') # "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9iaLiiUZ_l9"
      },
      "source": [
        "# Importing the image as variable img\n",
        "figName = './image_cell.tif'\n",
        "img = imread(str(figName)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dw1h-pNreUMt"
      },
      "source": [
        "## Understanding digital images"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src= https://github.com/MunskyGroup/uqbio2022/raw/master/files/files_image_processing/module_1_1/images/Slide3.png alt=\"drawing\" width=\"1200\"/>\n",
        "\n"
      ],
      "metadata": {
        "id": "n_7ggMeAjrUZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbpGVc5afAH9"
      },
      "source": [
        "What is a digital image?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UZmW3AXaQpg"
      },
      "source": [
        "# What is img?\n",
        "print('Image type =', type(img))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is essential to understand that images in Python are stored as NumPy objects.  [Numpy tutorial](https://colab.research.google.com/drive/1UlY-PBxhvvy_F29WbQ8be422BmKouBVs?usp=sharing)."
      ],
      "metadata": {
        "id": "2pu8D7shV8Vu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7RLPW07e9_8"
      },
      "source": [
        "\n",
        "What is the shape of the image?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhXrbP-6e7dk"
      },
      "source": [
        "print('Image dimensions, Shape =',img.shape )   #[T,Y,X,C]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Attributes in img object\n",
        "print([x for x in dir(img) if '__' not in x] ) #what functions (excluding internal functions, denoted by __xx__) does a list object have?"
      ],
      "metadata": {
        "id": "IWcnOKXt6Eaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFw7CDHXfJsM"
      },
      "source": [
        "Displaying a section of the image. Notice that an image is only a matrix of numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-1E5Y8Iv0Hs",
        "cellView": "form"
      },
      "source": [
        "#@title Image zoom in\n",
        "df = pd.DataFrame(img[0 , 250:260,250:260,0] ) # Converting the image into a pandas data frame\n",
        "# Plotting\n",
        "fig, ax = plt.subplots(1,2, figsize=(25, 10))\n",
        "ax[0].imshow(img[0,:,:,0],cmap='gray') \n",
        "ax[0].add_patch(Rectangle(xy=(250, 250),width=10,height=10,linewidth=3,color='yellow',fill=False)) # Rectangle in the image\n",
        "# Plotting the heatmap of a section in the image\n",
        "sn.heatmap(df, annot=True,cmap=\"gray\",fmt='d', ax=ax[1])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzeF30uxxCcO"
      },
      "source": [
        "# Plotting an image\n",
        "plt.figure(figsize=(7,7))\n",
        "selected_frame = 0\n",
        "selected_color_channel = 1\n",
        "plt.imshow(img[selected_frame,:,:,selected_color_channel],cmap='Greys_r') # Notice that only a time point and a color is plotted\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Notice the difference between plotting an image and ploting a time course.\n",
        "plt.plot([1,2,3,4])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZFiHoZwdc2IZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.choice(participants)"
      ],
      "metadata": {
        "id": "N51bwNQkIPC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice the difference between plotting an image and plotting a time course. In the image, the origin is on the top right corner. In contrast, in a time course plot the origin is located on the bottom right corner."
      ],
      "metadata": {
        "id": "if0zc699dnxr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPiYgZz3gSZG"
      },
      "source": [
        "From the [image's publication](https://www.biorxiv.org/content/10.1101/2020.04.03.024414v2) we can obtain the **metadata**. Indicating that the following information:\n",
        "\n",
        "Dimension  | Meaning |  Value\n",
        "---------|---------- |----------\n",
        "0   | Time        | 35 (frames)\n",
        "1   | Y-dimension | 512 pixels\n",
        "2   | X-dimension | 512 pixels\n",
        "3   | Color       | 3 color image (R,G,B)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMOU60u5k5Lq"
      },
      "source": [
        "<img src= https://github.com/MunskyGroup/uqbio2022/raw/master/files/files_image_processing/module_1_1/images/Slide4.png  alt=\"drawing\" width=\"1200\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "High-order tensor are also refered as Hyperstacks in software like [imagej](https://imagej.net/software/fiji/)."
      ],
      "metadata": {
        "id": "dOz301vf3eyo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_yUuV207STB"
      },
      "source": [
        "Intensity values in the image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ph7AsyjgYVj"
      },
      "source": [
        "# Minimum and maximum intensity values on the image\n",
        "max_intensity_value = np.max(img)\n",
        "min_intensity_value = np.min(img)\n",
        "\n",
        "quant_intensity_value = np.quantile(img, 0.9)    # 0.9 is equivalent to 90 percentile\n",
        "\n",
        "print('Maximum intensity : ', max_intensity_value)\n",
        "print('Minimum intensity : ', min_intensity_value)\n",
        "print('Quantile intensity: ', quant_intensity_value )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.choice(participants)"
      ],
      "metadata": {
        "id": "U-jxhGYlKrCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To understand the parameters that you need to pass to a method use the ```help``` function\n",
        "```\n",
        "help(method)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "ppQ0yOqbf-Gw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#help(np.quantile)"
      ],
      "metadata": {
        "id": "37CZnceggM4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2HVf-6R7WPz"
      },
      "source": [
        "Intensity distribution in the image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PN5SazcD7c52"
      },
      "source": [
        "# Plotting the intensity distribution for a specific time point and an specific channel\n",
        "plt.figure(figsize=(7,7))\n",
        "plt.hist(img[:,:,:,0].flatten(), bins=80,color='orangered')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Intensity Histogram')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOGE49vGg51F"
      },
      "source": [
        "Summary of image properties: \n",
        "\n",
        "* 4 dimensional tensor [T,Y,X,C]. \n",
        "* Numpy array\n",
        "* Intensity range (0, 6380)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESGFKhs-echL"
      },
      "source": [
        "\n",
        "### Monochromatic images "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVwyTqU-dny1"
      },
      "source": [
        "# Try to run the following line of code. Why doesn't it work?\n",
        "plt.imshow(img[0,:,:,0],cmap='Greys') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img.shape"
      ],
      "metadata": {
        "id": "wsLMB7NBL01n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.choice(participants)"
      ],
      "metadata": {
        "id": "gfk7Cyn-Lp4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_image = img[0,:,:,0]"
      ],
      "metadata": {
        "id": "NaezmXdkK85n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ff6g-sRFZxF1"
      },
      "source": [
        "# Visualzing a monochromatic image\n",
        "plt.figure(figsize=(7,7))\n",
        "plt.imshow(selected_image,cmap='gray') # Notice that only a time point and a color is plotted\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the image as the 3d dimension figure.\n",
        "space= np.arange(0, selected_image.shape[0], 1)\n",
        "xx, yy = np.meshgrid(space,space)\n",
        "fig = plt.figure(figsize=(15,7))\n",
        "# Set up the axes for the first plot\n",
        "ax = fig.add_subplot(1, 2, 1)\n",
        "ax.imshow(selected_image,cmap='gray') # Reds_r\n",
        "# Set up the axes for the second plot\n",
        "ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n",
        "ax2.plot_surface(xx, yy , selected_image,  rstride=20, cstride=20, shade=False, cmap='gray')\n",
        "ax2.view_init(20, 45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sXp78njsJ_Ue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Monochromatic images are normally associated with Black and White colors, but we can associate a different color map. Notice that this will only map the color intensity to a predefined colormap."
      ],
      "metadata": {
        "id": "MZfUkHOwk7uc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Colormaps\n",
        "\n",
        "cmaps = [('Perceptually Uniform Sequential', [\n",
        "            'viridis', 'plasma', 'inferno', 'magma', 'cividis']),\n",
        "         ('Sequential', [\n",
        "            'Greys', 'Purples', 'Blues', 'Greens', 'Oranges', 'Reds',\n",
        "            'YlOrBr', 'YlOrRd', 'OrRd', 'PuRd', 'RdPu', 'BuPu',\n",
        "            'GnBu', 'PuBu', 'YlGnBu', 'PuBuGn', 'BuGn', 'YlGn']),\n",
        "         ('Sequential (2)', [\n",
        "            'binary', 'gist_yarg', 'gist_gray', 'gray', 'bone', 'pink',\n",
        "            'spring', 'summer', 'autumn', 'winter', 'cool', 'Wistia',\n",
        "            'hot', 'afmhot', 'gist_heat', 'copper']),\n",
        "         ('Diverging', [\n",
        "            'PiYG', 'PRGn', 'BrBG', 'PuOr', 'RdGy', 'RdBu',\n",
        "            'RdYlBu', 'RdYlGn', 'Spectral', 'coolwarm', 'bwr', 'seismic']),\n",
        "         ('Cyclic', ['twilight', 'twilight_shifted', 'hsv']),\n",
        "         ('Qualitative', [\n",
        "            'Pastel1', 'Pastel2', 'Paired', 'Accent',\n",
        "            'Dark2', 'Set1', 'Set2', 'Set3',\n",
        "            'tab10', 'tab20', 'tab20b', 'tab20c']),\n",
        "         ('Miscellaneous', [\n",
        "            'flag', 'prism', 'ocean', 'gist_earth', 'terrain', 'gist_stern',\n",
        "            'gnuplot', 'gnuplot2', 'CMRmap', 'cubehelix', 'brg',\n",
        "            'gist_rainbow', 'rainbow', 'jet', 'nipy_spectral',\n",
        "            'gist_ncar'])]\n",
        "\n",
        "\n",
        "gradient = np.linspace(0, 1, 256)\n",
        "gradient = np.vstack((gradient, gradient))\n",
        "\n",
        "\n",
        "def plot_color_gradients(cmap_category, cmap_list):\n",
        "    # Create figure and adjust figure height to number of colormaps\n",
        "    nrows = len(cmap_list)\n",
        "    figh = 0.35 + 0.15 + (nrows + (nrows-1)*0.1)*0.22\n",
        "    fig, axs = plt.subplots(nrows=nrows, figsize=(6.4, figh))\n",
        "    fig.subplots_adjust(top=1-.35/figh, bottom=.15/figh, left=0.2, right=0.99)\n",
        "\n",
        "    axs[0].set_title(cmap_category + ' colormaps', fontsize=14)\n",
        "\n",
        "    for ax, cmap_name in zip(axs, cmap_list):\n",
        "        ax.imshow(gradient, aspect='auto', cmap=cmap_name)\n",
        "        ax.text(-.01, .5, cmap_name, va='center', ha='right', fontsize=10,\n",
        "                transform=ax.transAxes)\n",
        "\n",
        "    # Turn off *all* ticks & spines, not just the ones with colormaps.\n",
        "    for ax in axs:\n",
        "        ax.set_axis_off()\n",
        "\n",
        "\n",
        "for cmap_category, cmap_list in cmaps:\n",
        "    plot_color_gradients(cmap_category, cmap_list)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "GbDqJDNiIzsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using a colormap in a monochromatic image."
      ],
      "metadata": {
        "id": "5LCnO4W-3dOQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the image as the 3d dimension figure.\n",
        "space= np.arange(0, selected_image.shape[0], 1)\n",
        "xx, yy = np.meshgrid(space,space)\n",
        "fig = plt.figure(figsize=(15,7))\n",
        "# Set up the axes for the first plot\n",
        "ax = fig.add_subplot(1, 2, 1)\n",
        "ax.imshow(selected_image,cmap='Spectral') # coolwarm\n",
        "# Set up the axes for the second plot\n",
        "ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n",
        "ax2.plot_surface(xx, yy , selected_image,  rstride=20, cstride=20, shade=False, cmap='Spectral')\n",
        "ax2.view_init(20, 45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LoERMm5wKWtc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "An example of a monochromatic system is the black and white television.\n",
        "\n",
        "<img src= https://media.wired.com/photos/5eacb6979fa72e5901a7bfa3/191:100/w_5100,h_2670,c_limit/Gear-TV-binge-10079749.jpg alt=\"drawing\" width=\"800\"/>\n",
        "\n",
        "\n",
        "Image source: https://www.wired.com/story/what-we-keep-rebinging/\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0Ws_woBXnaYD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUpbCqxnNgXe"
      },
      "source": [
        "## Intensity in images (Bit depth)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSMC6pqVhmJd"
      },
      "source": [
        "Bit depth is the information stored on each pixel in the image. \n",
        "\n",
        "Bits  | Range of values: $2^n$\n",
        "---------|------------------\n",
        "1 bit    | 2 \n",
        "8 bit    | 256 \n",
        "12 bit   | 4096\n",
        "16 bit   | 65536\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RR-DZx0HpJDv"
      },
      "source": [
        "# https://stackoverflow.com/questions/46689428/convert-np-array-of-type-float64-to-type-uint8-scaling-values/46689933\n",
        "def convert(img, target_type_min, target_type_max, target_type):\n",
        "    '''\n",
        "    This function is intended to normalize img and change the image to the specified target_type\n",
        "      img: numpy array\n",
        "      target_type_min: int\n",
        "      target_type_max: int\n",
        "      target_type: str, optins are: np.uint\n",
        "    '''\n",
        "    imin = img.min()\n",
        "    imax = img.max()\n",
        "    a = (target_type_max - target_type_min) / (imax - imin)\n",
        "    b = target_type_max - a * imax\n",
        "    new_img = (a * img + b).astype(target_type)\n",
        "    return new_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdsuzjVaN2Px"
      },
      "source": [
        "Check this [link](https://numpy.org/doc/stable/user/basics.types.html) for a complete list of numpy data types."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHAqS4BZhlOx"
      },
      "source": [
        "# Normalizing and converting images between different bit-depths\n",
        "#Convert an image to unsigned byte format, with values in [0, 1]\n",
        "img_int1 = convert(img, 0,1,target_type=np.bool_)\n",
        "#Convert an image to unsigned byte format, with values in [0, 8]\n",
        "img_int3 = convert(img, 0,8,target_type=np.uint8)\n",
        "#Convert an image to unsigned byte format, with values in [0, 255]\n",
        "img_int8 = convert(img, 0,255,target_type=np.uint8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zY6HplbNnxTw"
      },
      "source": [
        "print('Range in 1-bit image: [', np.amin(img_int1),',' ,np.amax(img_int1) , ']' )\n",
        "print('Range in 3-bit image: [', np.amin(img_int3),',' ,np.amax(img_int3) , ']' )\n",
        "print('Range in 8-bit image: [', np.amin(img_int8),',' ,np.amax(img_int8) , ']' )\n",
        "print('Range in 16-bit image: [', np.amin(img),',' ,np.amax(img) , ']' ) # notice that the max value in this particular image is ~8K, but the maximum possible range in an int16 image is 65.5K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_aPRFIXkqXu"
      },
      "source": [
        "# Side-by-side comparison\n",
        "fig, ax = plt.subplots(1,3, figsize=(30, 20))\n",
        "ax[0].imshow(img_int3[0,:,:,0],cmap='gray')\n",
        "ax[0].set(title='3bit')\n",
        "ax[1].imshow(img_int8[0,:,:,0],cmap='gray')\n",
        "ax[1].set(title='8bit')\n",
        "ax[2].imshow(img[0,:,:,0],cmap='gray')\n",
        "ax[2].set(title='16bit')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PY5IHAFiEKDp"
      },
      "source": [
        "#### Values in the image for different bit depths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfxVTg3qEKRU"
      },
      "source": [
        "# Selecting a section of the images and converting this section into a data frame\n",
        "min_selection_area = 200\n",
        "max_selection_area = min_selection_area+10\n",
        "df_3bit = pd.DataFrame(img_int3[0,min_selection_area:max_selection_area,min_selection_area:max_selection_area,0] ) # Range in 3-bit image: [ 0 , 8 ]\n",
        "df_8bit = pd.DataFrame(img_int8[0,min_selection_area:max_selection_area,min_selection_area:max_selection_area,0] ) # Range in 8-bit image: [ 0 , 255 ]\n",
        "df_16bit = pd.DataFrame(img[0,min_selection_area:max_selection_area,min_selection_area:max_selection_area,0] ) # Range in 16-bit image: [ 0 , 65536 ]. In this particular image, the original maximum value is 6380\n",
        "\n",
        "# Plotting\n",
        "fig, ax = plt.subplots(1,3, figsize=(30, 7))\n",
        "# Plotting the heatmap of a section in the image\n",
        "sn.heatmap(df_3bit, annot=True,cmap=\"gray\",fmt='d', ax=ax[0])\n",
        "ax[0].set_title('3-bit image')\n",
        "sn.heatmap(df_8bit, annot=True,cmap=\"gray\",fmt='d', ax=ax[1])\n",
        "ax[1].set_title('8-bit image')\n",
        "sn.heatmap(df_16bit, annot=True,cmap=\"gray\",fmt='d', ax=ax[2])\n",
        "ax[2].set_title('16-bit image')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ar0uiRhfOlGT"
      },
      "source": [
        "#### File size for two different data types and bit depths\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwSKSyPYINNa"
      },
      "source": [
        "# Saving the images to disk\n",
        "tifffile.imwrite('temp_img_int8.tif', img_int8)\n",
        "tifffile.imwrite('temp_img_int16.tif', img)\n",
        "\n",
        "# Loading the images \n",
        "print(\"File size of the 8-bit image in Mb is: \", round(Path('temp_img_int8.tif').stat().st_size/1e6))\n",
        "print(\"File size of the 16-bit image in Mb is: \", round(Path('temp_img_int16.tif').stat().st_size/1e6))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0mGFJ8dM8zl"
      },
      "source": [
        "## Color images. \n",
        "\n",
        "3 Color Channels. Most image processing libraries use the \"consensus\" order RGB. A very important library for image processing ([OpenCV](https://opencv.org)) uses the order BGR!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting each one of the 3 colors independently\n",
        "fig, ax = plt.subplots(1,3, figsize=(20, 7))\n",
        "Red = img[0,:,:,0]\n",
        "ax[0].imshow(Red,cmap='Reds_r')\n",
        "Green = img[0,:,:,1]\n",
        "ax[1].imshow(Green,cmap='Greens_r')\n",
        "Blue = img[0,:,:,2]\n",
        "ax[2].imshow(Blue,cmap='Blues_r')\n",
        "ax[0].axis('off')\n",
        "ax[1].axis('off')\n",
        "ax[2].axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2IlD3VM7sGAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwLLE5sB0fUX"
      },
      "source": [
        "# Visualizing a color image\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(img_int8[0,:,:,:]) # Notice that only a time point and all colors are plotted\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uf1706KGOOv3"
      },
      "source": [
        "## Working with images in Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjUK0rpoOW6K"
      },
      "source": [
        "### Basic image manipulation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "it4IFSnMOqFp"
      },
      "source": [
        "#### Slicing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x_xa1Ow4kW1"
      },
      "source": [
        "In this section, we select parts of the image.\n",
        "\n",
        "The image is a numpy array with dimensions:\n",
        "```\n",
        "image[time, y-axis, x-axis, colors]\n",
        "```\n",
        "\n",
        "If we need to select the following elements:\n",
        "* timepoint (frame) 5\n",
        "* y-axis from 100 to 200 pixel\n",
        "* x-axis from 230 to 300 pixel\n",
        "* \"Green\" color (Color 1 in the standard format [R,G,B]),\n",
        "\n",
        "We would slice the numpy array as follows:\n",
        "\n",
        "```\n",
        "image[5, 99:200, 229:300, 1]\n",
        "```\n",
        "\n",
        "* Notice that when we slice [start: end(not including this value) :step]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.choice(participants)"
      ],
      "metadata": {
        "id": "wcJ0-aZlOj5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkxEwsc54BYp"
      },
      "source": [
        "# Ploting a subsection of the image\n",
        "# Time point: 0\n",
        "# Y-range: [99:200]\n",
        "# X-range: [229:300]\n",
        "# Channel: Green (1)\n",
        "plt.figure(figsize=(7,7))\n",
        "plt.imshow(img_int8[5, 99:200, 229:300 , 1],cmap='gray') # Notice that only a time point and a color is plotted\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRwow-M54eHs"
      },
      "source": [
        "# Ploting a subsection of the image\n",
        "# Time point: 22\n",
        "# Y-range: [230:300]\n",
        "# X-range: [155:350]\n",
        "# Channel: Blue (2)\n",
        "plt.figure(figsize=(7,7))\n",
        "plt.imshow(img_int8[22,230:300,155:350,2],cmap='gray') # Notice that only a time point and a color is plotted\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqf1CPcqOv_x"
      },
      "source": [
        "#### Thresholding"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_copy = img.copy() # Making a copy of our img\n",
        "plt.imshow(img_copy,cmap='gray') # Notice that only a time point and a color is plotted\n",
        "\n"
      ],
      "metadata": {
        "id": "BW2FvcR-Psk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3i09YvCR692X"
      },
      "source": [
        "# Making values less than the average equal to zero\n",
        "img_copy = img.copy() # Making a copy of our img\n",
        "img_section = img_copy[0,:,:,0] # Selecting a time point and color channel\n",
        "img_section[img_section>8000]=8000  # Thresholding image values larger than 1000 equal to 1000\n",
        "#img_section[img_section > np.mean(img_section) ]=np.mean(img_section)  # Thresholding image values larger than the mean equal to the mean\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(7,7))\n",
        "plt.imshow(img_section,cmap='gray') # Notice that only a time point and a color is plotted\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing the image after thresholding."
      ],
      "metadata": {
        "id": "ixahVdG8vQWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the image as the 3d dimension figure.\n",
        "space= np.arange(0, img_section.shape[0], 1)\n",
        "xx, yy = np.meshgrid(space,space)\n",
        "fig = plt.figure(figsize=(15,7))\n",
        "# Set up the axes for the first plot\n",
        "ax = fig.add_subplot(1, 2, 1)\n",
        "ax.imshow(img_section,cmap='gray') # coolwarm\n",
        "# Set up the axes for the second plot\n",
        "ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n",
        "ax2.plot_surface(xx, yy , img_section,  rstride=20, cstride=20, shade=False, cmap='Spectral')\n",
        "ax2.view_init(20, 45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ppdq8f4DvBSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmfGuqIbOlwY"
      },
      "source": [
        "## Filters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuLkk8wFLJvD"
      },
      "source": [
        "[Filters](https://ai.stanford.edu/~syyeung/cvweb/tutorial1.html) are used for:\n",
        "\n",
        "*   Noise reduction\n",
        "*   Edge detection\n",
        "*   Sharpening\n",
        "*   Blurring\n",
        "\n",
        "The mathematical operation is a 2D convolution. This convolution involves defining a smaller kernel matrix and applying the same mathematical operation to each pixel in the entire image. A more complete explanation can be found in this [video](https://youtu.be/8rrHTtUzyZA?t=72).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gbyFSTKkig2"
      },
      "source": [
        "<img src= https://github.com/MunskyGroup/uqbio2022/raw/master/files/files_image_processing/module_1_1/images/Slide5.png  alt=\"drawing\" width=\"1200\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoq0pDWRgago"
      },
      "source": [
        "##### Gaussian Filter. Noise reduction and blurring."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqPRfQwVgfNX"
      },
      "source": [
        "$G_\\sigma = \\frac{1}{2\\pi\\sigma^2}e{\\frac{x^2+y^2}{2\\sigma^2}}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ol0Hsh3RhCRn"
      },
      "source": [
        "# Section that creates the Gaussian Kernel Matrix\n",
        "def gaussian_kernel (size_matrix,sigma):\n",
        "  '''\n",
        "  This function returns a normalized gaussian kernel matrix\n",
        "  size_matrix : int\n",
        "  sigma: float\n",
        "  '''\n",
        "  ax = np.linspace(-(size_matrix - 1) / 2., (size_matrix - 1) / 2., size_matrix)\n",
        "  xx, yy = np.meshgrid(ax, ax)\n",
        "  kernel = np.exp(-0.5 * (np.square(xx) + np.square(yy)) / np.square(sigma)) \n",
        "  kernel = kernel/kernel.sum() # Normalizing to the sum\n",
        "  return kernel\n",
        "\n",
        "# Gaussian kernel matrix for different sigmas\n",
        "kernel_gaussian_sigma_3 = gaussian_kernel (size_matrix=20,sigma=3)\n",
        "kernel_gaussian_sigma_5 = gaussian_kernel (size_matrix=20,sigma=5)\n",
        "kernel_gaussian_sigma_10 = gaussian_kernel (size_matrix=20,sigma=10)\n",
        "\n",
        "print(sum(kernel_gaussian_sigma_3.flatten()))\n",
        "print(sum(kernel_gaussian_sigma_5.flatten()))\n",
        "print(sum(kernel_gaussian_sigma_10.flatten()))\n",
        "\n",
        "\n",
        "# Side-by-side comparison\n",
        "fig, ax = plt.subplots(1,3, figsize=(20, 10))\n",
        "ax[0].imshow(kernel_gaussian_sigma_3,cmap='gray')\n",
        "ax[0].set(title='Gaussian kernel $\\sigma$ =3')\n",
        "ax[1].imshow(kernel_gaussian_sigma_5,cmap='gray')\n",
        "ax[1].set(title='Gaussian kernel $\\sigma$ =5')\n",
        "ax[2].imshow(kernel_gaussian_sigma_10,cmap='gray')\n",
        "ax[2].set(title='Gaussian kernel $\\sigma$ =10')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.choice(participants)"
      ],
      "metadata": {
        "id": "fFqpKkxWRFiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqdWFAiwsBad"
      },
      "source": [
        "# Gaussian Kernel\n",
        "size_spot = 10\n",
        "spot_sigma = 2\n",
        "space = np.linspace(-(size_spot - 1) / 2., (size_spot - 1) / 2., size_spot)\n",
        "xx, yy = np.meshgrid(space, space)\n",
        "kernel = np.exp(-0.5 * (np.square(xx) + np.square(yy)) / np.square(spot_sigma)) \n",
        "kernel = kernel / np.amax(kernel) * 255  # Normalizing with respect to max and changing the range to [0,255]\n",
        "\n",
        "# Plotting\n",
        "fig = plt.figure(figsize=plt.figaspect(0.2))\n",
        "# Set up the axes for the first plot\n",
        "ax = fig.add_subplot(1, 2, 1)\n",
        "ax.imshow(kernel,cmap='Greens_r') # Reds_r\n",
        "# Set up the axes for the second plot\n",
        "ax = fig.add_subplot(1, 2, 2, projection='3d')\n",
        "ax.plot_surface(xx, yy, kernel, cmap='Greens_r')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSNOiAivMRgj"
      },
      "source": [
        "Example using [gaussian filter scipy](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.gaussian_filter.html). For a complete  list of filters in scipy, use the following [link](https://docs.scipy.org/doc/scipy/reference/ndimage.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCvsao4vLWN9"
      },
      "source": [
        "# Importing the library with the filter modules\n",
        "from scipy.ndimage import gaussian_filter\n",
        "\n",
        "img_copy = img.copy() # Making a copy of our img\n",
        "img_section = img_copy[0,:,:,0] # Selecting a timepoint and color channel\n",
        "\n",
        "# Applying the filter\n",
        "img_gaussian_filter_simga_1 = gaussian_filter(img_section, sigma=1)\n",
        "img_gaussian_filter_simga_10 = gaussian_filter(img_section, sigma=10)\n",
        "\n",
        "# Side-by-side comparison\n",
        "fig, ax = plt.subplots(1,3, figsize=(30, 10))\n",
        "ax[0].imshow(img_section,cmap='gray')\n",
        "ax[0].set(title='Original')\n",
        "\n",
        "# Noise reduction \n",
        "ax[1].imshow(img_gaussian_filter_simga_1,cmap='gray')\n",
        "ax[1].set(title='Gaussian Filter $\\sigma$ =1 Noise reduction')\n",
        "\n",
        "# Blurring\n",
        "ax[2].imshow(img_gaussian_filter_simga_10,cmap='gray')\n",
        "ax[2].set(title='Gaussian Filter $\\sigma$ =10 Image Blurring')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qt7m9Z77NDK9"
      },
      "source": [
        "Filters in scikit-image ([difference of gaussians](https://scikit-image.org/docs/stable/api/skimage.filters.html#skimage.filters.difference_of_gaussians)).\n",
        "\n",
        "This filter is used to locate elements between a low and a high value.\n",
        "\n",
        " For a complete list of filters in scikit-image, use the following [link](https://scikit-image.org/docs/stable/api/skimage.filters.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmrdlxfqN4vf"
      },
      "source": [
        "# Importing skimage filters module\n",
        "from skimage.filters import difference_of_gaussians\n",
        "\n",
        "img_copy = img.copy() # Making a copy of our img\n",
        "img_section = img_copy[0,:,:,2] # Selecting a time point and color channel\n",
        "\n",
        "# Applying the filter to our image\n",
        "img_diff_gaussians = difference_of_gaussians(img_section,low_sigma=1, high_sigma=10)\n",
        "#img_diff_gaussians = difference_of_gaussians(img_section,low_sigma=5, high_sigma=10)\n",
        "\n",
        "# Side-by-side comparison\n",
        "fig, ax = plt.subplots(1,2, figsize=(20, 10))\n",
        "ax[0].imshow(img_section,cmap='gray')\n",
        "ax[0].set(title='Original')\n",
        "ax[1].imshow(img_diff_gaussians,cmap='gray')\n",
        "ax[1].set(title='Difference of Gaussians')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xu1xikL-O3iP"
      },
      "source": [
        "#### Rotation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xfuu0S9lXd__"
      },
      "source": [
        "Simple rotation can be achieved by array manipulation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWG-CiIrXpDh"
      },
      "source": [
        "To rotate an image 90$^\\circ$, use the transpose property of the array ([transpose](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.T.html))."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G___ihkhYfcE"
      },
      "source": [
        "img_copy = img.copy() # Making a copy of our img\n",
        "img_section = img_copy[0,:,:,0] # Selecting a time point and color channel\n",
        "transposed_img = img_section.T # Transposed property in a numpy array\n",
        "\n",
        "# Side-by-side comparison\n",
        "fig, ax = plt.subplots(1,2, figsize=(20, 10))\n",
        "ax[0].imshow(img_section,cmap='gray')\n",
        "ax[0].set(title='Original')\n",
        "ax[1].imshow(transposed_img,cmap='gray')\n",
        "ax[1].set(title= 'Image rotated by 90 degrees' )\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aV3x-0XvWdgR"
      },
      "source": [
        "\n",
        "Library ([rotate scipy](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.rotate.html#scipy.ndimage.rotate))."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYkFWx7_LUc2"
      },
      "source": [
        "# Importing skimage rotation module\n",
        "from scipy import ndimage as nd\n",
        "\n",
        "img_copy = img.copy() # Making a copy of our img\n",
        "img_section = img_copy[0,:,:,0] # Selecting a time point and color channel\n",
        "\n",
        "# Rotating the image to a given angle\n",
        "selected_angle = 37\n",
        "img_rotation = nd.rotate(img_section, angle=selected_angle)\n",
        "\n",
        "# Side-by-side comparison\n",
        "fig, ax = plt.subplots(1,2, figsize=(20, 10))\n",
        "ax[0].imshow(img_section,cmap='gray')\n",
        "ax[0].set(title='Original')\n",
        "ax[1].imshow(img_rotation,cmap='gray')\n",
        "ax[1].set(title= 'Image rotated by '+str(selected_angle)+ ' degrees' )\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVqFESd_PFNk"
      },
      "source": [
        "#### Image transformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2I99VaYAJ5pE"
      },
      "source": [
        "Consists of applying rotation, scaling, and translation processes to the image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-dok6uhYYp-"
      },
      "source": [
        "List of available [transformations in skimage](https://scikit-image.org/docs/stable/auto_examples/transform/plot_transform_types.html). Blog with more information about [applying transformations to images](https://towardsdatascience.com/image-processing-with-python-applying-homography-for-image-warping-84cd87d2108f)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df60Z4LwYeen"
      },
      "source": [
        "# Importing skimage transformation module\n",
        "from skimage import transform\n",
        "\n",
        "img_copy = img.copy() # Making a copy of our img\n",
        "img_section = img_copy[0,:,:,0] # Selecting a timepoint and color channel\n",
        "\n",
        "#  Transformation matrix\n",
        "tform = transform.SimilarityTransform(\n",
        "    scale = 0.95,                  # float, scaling value\n",
        "    rotation = np.pi/90,           # Rotation angle in counter-clockwise direction as radians. pi/180 rad = 1 degrees\n",
        "    translation=(100, 1))          # (x, y) values for translation\n",
        "print('Transformation matrix : \\n', tform.params , '\\n')\n",
        "\n",
        "# Applying the transformation\n",
        "tf_img = transform.warp(img_section, tform.inverse)\n",
        "\n",
        "# Side-by-side comparison\n",
        "fig, ax = plt.subplots(1,2, figsize=(20, 10))\n",
        "ax[0].imshow(img_section,cmap='gray')\n",
        "ax[0].set(title='Original')\n",
        "ax[1].imshow(tf_img,cmap='gray')\n",
        "ax[1].set_title('Transformation')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This process is used before merging images taken from multiple cameras. Image registration [Check this video](https://www.youtube.com/watch?v=nNZJw0kgzdg&list=LL&index=7)\n",
        "\n",
        "<img src= https://github.com/MunskyGroup/uqbio2022/raw/master/files/files_image_processing/module_1_1/images/Slide7.png  alt=\"drawing\" width=\"1200\"/>"
      ],
      "metadata": {
        "id": "9ERlWkn7xnu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.choice(participants)"
      ],
      "metadata": {
        "id": "tALKeJ2lZR35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ff6-FeqUA9he"
      },
      "source": [
        "## Working with a sequence of images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZfytq3ss_vI"
      },
      "source": [
        "### Video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3dHENYartCw",
        "cellView": "form"
      },
      "source": [
        "# @title Animation code\n",
        "# blit=True re-draws only the parts that have changed\n",
        "fig,axes = plt.subplots(1,3,dpi=120,figsize=(8,3))\n",
        "i=0\n",
        "# Define inital frames\n",
        "Red = img[i,:,:,0]\n",
        "im1 = axes[0].imshow(Red,cmap='Reds_r')\n",
        "Green = img[i,:,:,1]\n",
        "im2 = axes[1].imshow(Green,cmap='Greens_r')\n",
        "Blue = img[i,:,:,2]\n",
        "im3 =  axes[2].imshow(Blue,cmap='Blues_r')\n",
        "axes[0].axis('off')\n",
        "axes[1].axis('off')\n",
        "axes[2].axis('off')\n",
        "\n",
        "def movieFrame(i):\n",
        "  Red = img[i,:,:,0]\n",
        "  Green = img[i,:,:,1]\n",
        "  Blue = img[i,:,:,2]\n",
        "  images = [Red,Green,Blue]\n",
        "  image_handles = [im1,im2,im3]\n",
        "  for k,image_n in enumerate(images):\n",
        "    image_handles[k].set_array(images[k])\n",
        "  return image_handles\n",
        "  \n",
        "plt.close()\n",
        "anim = animation.FuncAnimation(fig, movieFrame, frames=img.shape[0], interval=20, blit=True)\n",
        "from IPython.display import HTML\n",
        "HTML(anim.to_html5_video())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJJ1bUOpqH-M"
      },
      "source": [
        "### Images with 3-dimensional space, fluorescence in situ hybridization (FISH) images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZf1xgAxqORF"
      },
      "source": [
        "# Downloading the image to Colab\n",
        "%%capture\n",
        "drive = pathlib.Path(\"/content\")\n",
        "found_files = list(drive.glob('**/FISH_example.zip'))\n",
        "if len(found_files) != 0:\n",
        "  print(f\"File already downloaded and can be found in {found_files[0]}.\")\n",
        "else:\n",
        "  !wget --no-check-certificate 'https://www.dropbox.com/s/6y7yqlmlnnxm7rs/FISH_example.zip?dl=0' -r -A 'uc*' -e robots=off -nd -O 'FISH_example.zip'\n",
        "  # !wget --no-check-certificate 'https://www.dropbox.com/s/1ZR6nY9kscgLEefZFwBPwsbog-JlVwE2B/FISH_example.zip?dl=0' -r -A 'uc*' -e robots=off -nd -O 'FISH_example.zip'\n",
        "  !unzip FISH_example.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jIyWYmFtfdE"
      },
      "source": [
        "# Importing the image as variable img\n",
        "figName_FISH = './FISH_example.tif'\n",
        "img_FISH = imread(figName_FISH) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXtyYPupsvuO"
      },
      "source": [
        "# This image has dimension [Z,Y,X]\n",
        "print(img_FISH.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8d5oSuDxjRS"
      },
      "source": [
        "# Removing outliers\n",
        "max_val = np.percentile(img_FISH, 99)\n",
        "img_FISH [img_FISH> max_val] = max_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCxd_Fm1tsfK"
      },
      "source": [
        "# Plotting the FISH image\n",
        "fig, ax = plt.subplots(1,img_FISH.shape[0], figsize=(30, 10))\n",
        "for i in range (0,img_FISH.shape[0]):\n",
        "  ax[i].imshow(img_FISH[i,:,:],cmap='gray')\n",
        "  ax[i].set(title= ['Z=',str(i)])\n",
        "  ax[i].axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGuMhGoPyu0I"
      },
      "source": [
        "Moving in and out of focus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjAK5e47yHaP",
        "cellView": "form"
      },
      "source": [
        "#@title FISH visualizer\n",
        "def FISH_viewer( z_value):\n",
        "    '''\n",
        "    This function is intended to display an image from an array of images (specifically, video: img_int8). img_int8 is a numpy array with dimension [T,Y,X,C].\n",
        "    drop_channel : str with options 'Ch_0', 'Ch_1', 'Ch_2', 'All'\n",
        "    time: int with range 0 to the number of frames in video.\n",
        "    '''\n",
        "    plt.figure(1)\n",
        "    temp_FISH_image = img_FISH[z_value,:,:]    \n",
        "    plt.imshow(temp_FISH_image,cmap='gray')\n",
        "    plt.show()\n",
        "\n",
        "# Defining an interactive plot\n",
        "interactive_plot = interactive(FISH_viewer,z_value = widgets.IntSlider(min=0,max=img_FISH.shape[0]-1,step=1,value=0,description='z-value'))       # time slider parameters\n",
        "# Creates the controls\n",
        "controls = HBox(interactive_plot.children[:-1], layout = Layout(flex_flow='row wrap'))\n",
        "# Creates the outputs\n",
        "output = interactive_plot.children[-1]\n",
        "\n",
        "# Display the controls and output as an interactive widget\n",
        "display(VBox([controls, output]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FLGKKdKmR_T"
      },
      "source": [
        "## Operations on multiple images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYkIt7-Okq9U"
      },
      "source": [
        "<img src= https://github.com/MunskyGroup/uqbio2022/raw/master/files/files_image_processing/module_1_1/images/Slide6.png  alt=\"drawing\" width=\"1200\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVOEK4mKzCul"
      },
      "source": [
        "Maximum projections"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aq7o2XFay0bC"
      },
      "source": [
        "# Making a copy of our sequence of images\n",
        "img_FISH_copy = img_FISH.copy() # Making a copy of our img\n",
        "\n",
        "# Applying a maximum projection\n",
        "#img_max_z_projection = np.max(img_FISH, axis=0)\n",
        "img_max_z_projection = np.mean(img_FISH, axis=0)\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(7,7))\n",
        "plt.imshow(img_max_z_projection,cmap='Greys_r')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Printing results\n",
        "print('Dimensions on the original sequence of images :', img_FISH.shape, '\\n')\n",
        "print('Dimensions on the maximum projection :', img_max_z_projection.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LKgKz3UdL1c"
      },
      "source": [
        "Normalizing intensity for every channel and time point"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Max-Min Normalization\n",
        "\n",
        "$img_{norm} = \\frac{img-min(img)}{max(img)-min(img)}$"
      ],
      "metadata": {
        "id": "5tQxaYCN2X0M"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X873jFGndLCK"
      },
      "source": [
        "img_normalized = np.zeros_like(img)   # Preallocating memory\n",
        "number_timepoints, y_dim, x_dim, number_channels = img.shape[0], img.shape[1], img.shape[2], img.shape[3] # Obtaining the dimensions size\n",
        "\n",
        "# Normalization using a nested for-loop\n",
        "for index_channels in range (number_channels): # Iteration for every channel\n",
        "    for index_time in range (number_timepoints): # Iterating for every time point\n",
        "        max_val = np.amax(img[index_time,:,:,index_channels])\n",
        "        min_val = np.amin(img[index_time,:,:,index_channels])\n",
        "        img_normalized[index_time,:,:,index_channels] = (img[index_time,:,:,index_channels]-min_val) / (max_val-min_val) # Normalization \n",
        "\n",
        "# Printing the output\n",
        "print('Range values in the original sequence of images: (' , np.amin(img) ,',', np.amax(img) ,')\\n' )\n",
        "print('Range values in the normalized sequence of images: (' , np.amin(img_normalized) ,',', np.amax(img_normalized) ,')\\n' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh_Ubv6ARPFM"
      },
      "source": [
        "Transposing dimensions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpN1ZaXqRRcp"
      },
      "source": [
        "# Making a copy of our sequence of images\n",
        "img_int8_copy = img_int8.copy() # Making a copy of our img [T, Y, X, C]\n",
        "\n",
        "# Reshaping the video. Changing the Time position (0) to the last place (3).  [C, Y, X, T]\n",
        "img_transposed = np.transpose(img_int8_copy, (3, 1, 2, 0))\n",
        "\n",
        "# Printing results\n",
        "print('Dimensions on the original sequence of images :', img_int8_copy.shape, '\\n')\n",
        "print('Dimensions on the maximum projection :', img_transposed.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yq-ZVAD4r3Il"
      },
      "source": [
        "print(img_int8_copy.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dMLxd-wu2zh"
      },
      "source": [
        "---\n",
        "# Short test\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11KpYp5Gu5YV"
      },
      "source": [
        "Please complete the following [test](https://docs.google.com/forms/d/e/1FAIpQLSdyAuiq2lID3XWgYcdLQbBzLVMwhdd6GMSBSPy9fW_NdZmq_Q/viewform?usp=sf_link)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QoPmE6JuO37"
      },
      "source": [
        "---\n",
        "\n",
        "# Practice Problems\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please enter your answers for each of the following questions by adding text or code to fill in the blanks.  \n",
        "\n",
        "##Basic Image Processing - Workbook Completion Requirements:##\n",
        "To obtain credit for this lesson, each student should (i) complete all blanks for questions Q1-Q7.\n",
        "\n",
        "To obtain a certificate for the course, you must complete a minimum of five notebooks from Modules 1-4 (please note that preliminary notebooks from Module 0 will not be accepted) and submit them together via email before August 15, 2022. Please submit your completed notebooks to qbio_summer_school@colostate.edu"
      ],
      "metadata": {
        "id": "JD_F3c7Y9IzZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading the image from figshare SupFig1c_BG_MAX_Cell04.tif\n",
        "urls = ['https://ndownloader.figshare.com/files/26751209','https://ndownloader.figshare.com/files/26751203','https://ndownloader.figshare.com/files/26751212','https://ndownloader.figshare.com/files/26751218']\n",
        "print('Downloading file...')\n",
        "urllib.request.urlretrieve(urls[2], './image_cell.tif') # \n",
        "# Importing the image as variable img_test\n",
        "figName = './image_cell.tif'\n",
        "img_test = imread(str(figName)) \n",
        "print('File downloaded...')"
      ],
      "metadata": {
        "id": "7zvk_WLb9HTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The following image has the following dimensions:  [T,Y,X,C]\n",
        "print(img_test.shape)   "
      ],
      "metadata": {
        "id": "HcXG24e5Er22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the test image\n",
        "fig, ax = plt.subplots(1,img_test.shape[3], figsize=(20, 7))\n",
        "for i in range (0,img_test.shape[3]):\n",
        "  ax[i].imshow(img_test[0,:,:,i],cmap='gray')\n",
        "  ax[i].set(title= 'ch ='+str(i))\n",
        "  ax[i].axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ct6D069IEmHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Easy Questions"
      ],
      "metadata": {
        "id": "L7_840TvITi5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCElMADXuRwf"
      },
      "source": [
        "* Q1.  Plot the third color channel at time point 23 of the test image."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add your code with your response here:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5bLvW__DFX29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Q2. Using the test image reduce in a half the intensity in the second color channel. Make sure that the resulting image has data type ```numpy.uint16```\n",
        "\n"
      ],
      "metadata": {
        "id": "rvO6iVubFcI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add your code with your response here:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8hU5K_vVFf7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Q3. Using the test make a new image that is mirror flipped vertically. "
      ],
      "metadata": {
        "id": "VOHbb54sFYNX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add your code with your response here:\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SNA53C5GFnFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Q4. Using the test image make an image that is mirror flipped horizontally."
      ],
      "metadata": {
        "id": "LRC1_RjGFnhE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add your code with your response here:\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MNKccnNPFnvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Moderate Questions"
      ],
      "metadata": {
        "id": "uY1B-t60IaNK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Q5. Using the test image make a copy of it and create a new image that is compressed to 1/2 resolution in X, and 1/3 resolution in Y. Make this process for only one color channel and a single frame (time point). Plot your resulting image."
      ],
      "metadata": {
        "id": "ri-OTCDSIe-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add your code with your response here:\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TERsbc8PIeQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advanced Questions"
      ],
      "metadata": {
        "id": "CfFyX7OMIPr-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Q6. Using the test image, create a new image tensor which is centered around the brightest pixel of the image and is a 50x50 cutout of the original video/tensor. Do this before and after applying a Gaussian filter."
      ],
      "metadata": {
        "id": "Trzn4efoF2R4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add your code with your response here:\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "P7xCu1VKF5BI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7. Using the test image, create a maximum projection for all the frames (time points) in the image. "
      ],
      "metadata": {
        "id": "qmA28GuQI-UX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add your code with your response here:\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kWiEnU9cJP3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8. Create a widget to display the test image interactively using the following library [ipywidgets](https://ipywidgets.readthedocs.io/en/latest/). Specifically, create a widget that allows you to select each channel from a **Dropdown** and choose a given frame using an **Intslider**. \n",
        "\n"
      ],
      "metadata": {
        "id": "HUziOuMq4gqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add your code with your response here:\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KzSmqYxN4g1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFBJIdmvbTKM"
      },
      "source": [
        "# References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SzkyFx2bYPG"
      },
      "source": [
        "* Images downloaded from https://figshare.com from publication: \"Forero-Quintero, L.S., Raymond, W., Handa, T. et al. Live-cell imaging reveals the spatiotemporal organization of endogenous RNA polymerase II phosphorylation at a single gene. Nat Commun 12, 3158 (2021). https://doi.org/10.1038/s41467-021-23417-0\"\n",
        "\n",
        "* Gonzalez, Rafael & Faisal, Zahraa. (2019). Digital Image Processing Second Edition. \n",
        ">\n"
      ]
    }
  ]
}